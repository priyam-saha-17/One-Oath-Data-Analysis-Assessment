{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e61f3c8",
   "metadata": {},
   "source": [
    "## QUESTION 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e46bb01",
   "metadata": {},
   "source": [
    "### Q.1 \n",
    "Group the given data into four categories for Bright and Dark traits. Where categories are A(1-0),B(3-2), C(6-4) and D(7-   10). For each student calculate the average of bright traits and dark traits and assign them into a category.\n",
    "\n",
    "Bright traits: LOGIC, CONCENTRATION, FOCUS, COGNITIVE SKILL, RETENTION POWER, HARD WORKING, STUDY HABIT, CONSCIOUSNESS.\n",
    "\n",
    "Dark Trait: SILLY MISTAKES,KNOWLEDGE GAP, IMPULSIVE, LEARNING GAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988814e2",
   "metadata": {},
   "source": [
    "#### Refer :-     \"Data.csv\" in Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e34f29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>ROLL</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>BRIGHT TRAITS</th>\n",
       "      <th>DARK TRAITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Srishti Shahi</td>\n",
       "      <td>28</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEBMALYA LAHIRI</td>\n",
       "      <td>8</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ananya Naskar</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deepsikha Naskar</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aditi Kuilya</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rohan Kundu</td>\n",
       "      <td>17</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Soumyadeep Purkait</td>\n",
       "      <td>27</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shiven Singh Rajput</td>\n",
       "      <td>23</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harshavardhan Chakraborty</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Simran Ghosh</td>\n",
       "      <td>25</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sunita Biswal</td>\n",
       "      <td>31</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bishwarup Das</td>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Subham Bairagi</td>\n",
       "      <td>29</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         NAME ROLL SECTION BRIGHT TRAITS DARK TRAITS\n",
       "0               Srishti Shahi   28       A             A           D\n",
       "1             DEBMALYA LAHIRI    8       A             A           D\n",
       "2               Ananya Naskar    4       A             B           C\n",
       "3            Deepsikha Naskar    9       A             A           D\n",
       "4                Aditi Kuilya    2       A             A           D\n",
       "5                 Rohan Kundu   17       A             B           C\n",
       "6          Soumyadeep Purkait   27       A             B           D\n",
       "7         Shiven Singh Rajput   23       A             B           C\n",
       "8   Harshavardhan Chakraborty   10       A             C           C\n",
       "9                Simran Ghosh   25       A             B           C\n",
       "10              Sunita Biswal   31       A             B           C\n",
       "11              Bishwarup Das    6       A             A           D\n",
       "12             Subham Bairagi   29       A             A           D"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "student_dict = {\"NAME\": [], \"ROLL\": [], \"SECTION\": [], \"BRIGHT TRAITS\": [], \"DARK TRAITS\": []}\n",
    "\n",
    "with open(\"Input Data/Data .csv\", mode =\"r\")as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    f = 1\n",
    "    for line in csvFile:\n",
    "        if f == 1:\n",
    "            f = 0\n",
    "            continue\n",
    "        else:\n",
    "            bt = 0\n",
    "            for j in range(3, 11):\n",
    "                bt += float(line[j])\n",
    "            bt = int(bt // 8)\n",
    "            dt = 0\n",
    "            for j in range(11, 15):\n",
    "                dt += float(line[j])\n",
    "            dt = int(dt // 4)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if 0<= bt and bt <= 1:\n",
    "                bt = 'A'\n",
    "            elif 2<= bt and bt <= 3:\n",
    "                bt = 'B'\n",
    "            elif 4<= bt and bt <= 6:\n",
    "                bt = 'C'\n",
    "            elif 7<= bt and bt <= 10:\n",
    "                bt = 'D'\n",
    "                \n",
    "            if 0<= dt and dt <= 1:\n",
    "                dt = 'A'\n",
    "            elif 2<= dt and dt <= 3:\n",
    "                dt = 'B'\n",
    "            elif 4<= dt and dt <= 6:\n",
    "                dt = 'C'\n",
    "            elif 7<= dt and dt <= 10:\n",
    "                dt = 'D'\n",
    "                \n",
    "                \n",
    "                \n",
    "            student_dict['NAME'].append(line[0])\n",
    "            student_dict['ROLL'].append(line[1])\n",
    "            student_dict['SECTION'].append(line[2])\n",
    "            student_dict['BRIGHT TRAITS'].append(bt)\n",
    "            student_dict['DARK TRAITS'].append(dt)\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict(student_dict)\n",
    "  \n",
    "df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "59dc41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Output Data/Q1. Student Categories.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929b564",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e0085",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f48712",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313393c",
   "metadata": {},
   "source": [
    "## QUESTION 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8a640",
   "metadata": {},
   "source": [
    "### Q.2 \n",
    "\n",
    "Write a Python program that counts the frequency of each word in a given text document. Remove any punctuation marks and convert all words to lowercase befor counting. \n",
    "\n",
    "Display the top 5 most frequent words along with their frequencies. \n",
    "Also calculate the below parameters.\n",
    "\n",
    "\n",
    "\n",
    "The formulas for calculations are :\n",
    "\n",
    "Positive Score: This score is calculated by assigning the value of +1 for each word if found in the Positive Dictionary and then adding up all the values.\n",
    "\n",
    "Negative Score: This score is calculated by assigning the value of -1 for each word if found in the Negative Dictionary and then adding up all the values. We multiply the score with -1 so that the score is a positive number.\n",
    "\n",
    "Polarity Score: This is the score that determines if a given text is positive or negative in nature. It is calculated by using the formula:\n",
    "        Polarity Score = (Positive Score â€“ Negative Score)/ ((Positive Score + Negative Score) + 0.000001)\n",
    "\n",
    "Range is from -1 to +1\n",
    "\n",
    "Average Sentence Length = the number of words / the number of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7429572f",
   "metadata": {},
   "source": [
    "#### Refer :-     \"paragraph.txt\" , \"positive-words.txt\", \"negative-words.txt\"  in Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41f243d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural\n",
      "language\n",
      "processing\n",
      "nlp\n",
      "is\n",
      "a\n",
      "branch\n",
      "of\n",
      "artificial\n",
      "intelligence\n",
      "that\n",
      "focuses\n",
      "on\n",
      "enabling\n",
      "computers\n",
      "to\n",
      "understand\n",
      "interpret\n",
      "and\n",
      "generate\n",
      "human\n",
      "language\n",
      "it\n",
      "combines\n",
      "principles\n",
      "from\n",
      "linguistics\n",
      "computer\n",
      "science\n",
      "and\n",
      "machine\n",
      "learning\n",
      "to\n",
      "bridge\n",
      "the\n",
      "gap\n",
      "between\n",
      "human\n",
      "communication\n",
      "and\n",
      "machine\n",
      "understanding\n",
      "nlp\n",
      "plays\n",
      "a\n",
      "crucial\n",
      "role\n",
      "in\n",
      "numerous\n",
      "applications\n",
      "including\n",
      "language\n",
      "translation\n",
      "sentiment\n",
      "analysis\n",
      "speech\n",
      "recognition\n",
      "question-answering\n",
      "systems\n",
      "chatbots\n",
      "and\n",
      "much\n",
      "more\n",
      "in\n",
      "this\n",
      "paragraph\n",
      "we\n",
      "will\n",
      "explore\n",
      "the\n",
      "fundamental\n",
      "concepts\n",
      "techniques\n",
      "and\n",
      "advancements\n",
      "in\n",
      "nlp\n",
      "at\n",
      "its\n",
      "core\n",
      "nlp\n",
      "involves\n",
      "the\n",
      "processing\n",
      "and\n",
      "analysis\n",
      "of\n",
      "vast\n",
      "amounts\n",
      "of\n",
      "textual\n",
      "data\n",
      "one\n",
      "of\n",
      "the\n",
      "key\n",
      "challenges\n",
      "in\n",
      "nlp\n",
      "is\n",
      "to\n",
      "convert\n",
      "unstructured\n",
      "text\n",
      "into\n",
      "a\n",
      "structured\n",
      "representation\n",
      "that\n",
      "machines\n",
      "can\n",
      "comprehend\n",
      "tokenization\n",
      "is\n",
      "the\n",
      "first\n",
      "step\n",
      "where\n",
      "the\n",
      "text\n",
      "is\n",
      "divided\n",
      "into\n",
      "individual\n",
      "words\n",
      "or\n",
      "tokens\n",
      "these\n",
      "tokens\n",
      "are\n",
      "then\n",
      "analyzed\n",
      "for\n",
      "their\n",
      "meaning\n",
      "and\n",
      "relationships\n",
      "syntax\n",
      "analysis\n",
      "also\n",
      "known\n",
      "as\n",
      "parsing\n",
      "helps\n",
      "to\n",
      "determine\n",
      "the\n",
      "grammatical\n",
      "structure\n",
      "of\n",
      "sentences\n",
      "identifying\n",
      "the\n",
      "subject\n",
      "object\n",
      "verb\n",
      "and\n",
      "other\n",
      "elements\n",
      "understanding\n",
      "the\n",
      "meaning\n",
      "of\n",
      "words\n",
      "and\n",
      "their\n",
      "relationships\n",
      "is\n",
      "crucial\n",
      "in\n",
      "nlp\n",
      "word\n",
      "sense\n",
      "disambiguation\n",
      "is\n",
      "the\n",
      "process\n",
      "of\n",
      "determining\n",
      "the\n",
      "correct\n",
      "meaning\n",
      "of\n",
      "a\n",
      "word\n",
      "based\n",
      "on\n",
      "its\n",
      "context\n",
      "this\n",
      "task\n",
      "is\n",
      "complex\n",
      "due\n",
      "to\n",
      "the\n",
      "presence\n",
      "of\n",
      "homonyms\n",
      "and\n",
      "polysemous\n",
      "words\n",
      "to\n",
      "tackle\n",
      "this\n",
      "challenge\n",
      "various\n",
      "algorithms\n",
      "and\n",
      "resources\n",
      "such\n",
      "as\n",
      "semantic\n",
      "networks\n",
      "knowledge\n",
      "bases\n",
      "and\n",
      "word\n",
      "embeddings\n",
      "have\n",
      "been\n",
      "developed\n",
      "word\n",
      "embeddings\n",
      "such\n",
      "as\n",
      "word2vec\n",
      "and\n",
      "glove\n",
      "represent\n",
      "words\n",
      "as\n",
      "dense\n",
      "vectors\n",
      "in\n",
      "a\n",
      "high-dimensional\n",
      "space\n",
      "capturing\n",
      "their\n",
      "semantic\n",
      "and\n",
      "syntactic\n",
      "similarities\n",
      "sentiment\n",
      "analysis\n",
      "is\n",
      "another\n",
      "vital\n",
      "application\n",
      "of\n",
      "nlp\n",
      "which\n",
      "involves\n",
      "determining\n",
      "the\n",
      "sentiment\n",
      "or\n",
      "emotional\n",
      "tone\n",
      "expressed\n",
      "in\n",
      "a\n",
      "piece\n",
      "of\n",
      "text\n",
      "sentiment\n",
      "analysis\n",
      "techniques\n",
      "can\n",
      "range\n",
      "from\n",
      "simple\n",
      "rule-based\n",
      "approaches\n",
      "to\n",
      "sophisticated\n",
      "machine\n",
      "learning\n",
      "models\n",
      "these\n",
      "models\n",
      "are\n",
      "trained\n",
      "on\n",
      "labeled\n",
      "datasets\n",
      "to\n",
      "classify\n",
      "text\n",
      "into\n",
      "positive\n",
      "negative\n",
      "or\n",
      "neutral\n",
      "sentiment\n",
      "categories\n",
      "sentiment\n",
      "analysis\n",
      "finds\n",
      "applications\n",
      "in\n",
      "social\n",
      "media\n",
      "monitoring\n",
      "customer\n",
      "feedback\n",
      "analysis\n",
      "brand\n",
      "reputation\n",
      "management\n",
      "and\n",
      "market\n",
      "research\n",
      "machine\n",
      "translation\n",
      "one\n",
      "of\n",
      "the\n",
      "most\n",
      "prominent\n",
      "applications\n",
      "of\n",
      "nlp\n",
      "involves\n",
      "the\n",
      "automatic\n",
      "translation\n",
      "of\n",
      "text\n",
      "from\n",
      "one\n",
      "language\n",
      "to\n",
      "another\n",
      "early\n",
      "machine\n",
      "translation\n",
      "systems\n",
      "relied\n",
      "on\n",
      "rule-based\n",
      "approaches\n",
      "that\n",
      "required\n",
      "extensive\n",
      "linguistic\n",
      "knowledge\n",
      "and\n",
      "manual\n",
      "rule\n",
      "creation\n",
      "however\n",
      "with\n",
      "the\n",
      "advent\n",
      "of\n",
      "neural\n",
      "machine\n",
      "translation\n",
      "models\n",
      "such\n",
      "as\n",
      "sequence-to-sequence\n",
      "models\n",
      "and\n",
      "transformer\n",
      "architectures\n",
      "the\n",
      "accuracy\n",
      "and\n",
      "fluency\n",
      "of\n",
      "machine\n",
      "translations\n",
      "have\n",
      "significantly\n",
      "improved\n",
      "these\n",
      "models\n",
      "learn\n",
      "to\n",
      "translate\n",
      "by\n",
      "training\n",
      "on\n",
      "large\n",
      "parallel\n",
      "corpora\n",
      "capturing\n",
      "the\n",
      "statistical\n",
      "patterns\n",
      "and\n",
      "linguistic\n",
      "structures\n",
      "of\n",
      "different\n",
      "languages\n",
      "question-answering\n",
      "systems\n",
      "aim\n",
      "to\n",
      "provide\n",
      "accurate\n",
      "and\n",
      "relevant\n",
      "responses\n",
      "to\n",
      "user\n",
      "queries\n",
      "these\n",
      "systems\n",
      "leverage\n",
      "techniques\n",
      "from\n",
      "information\n",
      "retrieval\n",
      "natural\n",
      "language\n",
      "understanding\n",
      "and\n",
      "knowledge\n",
      "representation\n",
      "they\n",
      "analyze\n",
      "user\n",
      "queries\n",
      "extract\n",
      "relevant\n",
      "information\n",
      "from\n",
      "large\n",
      "text\n",
      "corpora\n",
      "or\n",
      "knowledge\n",
      "bases\n",
      "and\n",
      "generate\n",
      "concise\n",
      "answers\n",
      "question-answering\n",
      "systems\n",
      "have\n",
      "gained\n",
      "prominence\n",
      "with\n",
      "the\n",
      "development\n",
      "of\n",
      "virtual\n",
      "assistants\n",
      "and\n",
      "chatbots\n",
      "enabling\n",
      "users\n",
      "to\n",
      "interact\n",
      "with\n",
      "machines\n",
      "using\n",
      "natural\n",
      "language\n",
      "speech\n",
      "recognition\n",
      "is\n",
      "another\n",
      "domain\n",
      "where\n",
      "nlp\n",
      "techniques\n",
      "are\n",
      "extensively\n",
      "utilized\n",
      "speech\n",
      "recognition\n",
      "systems\n",
      "convert\n",
      "spoken\n",
      "language\n",
      "into\n",
      "written\n",
      "text\n",
      "enabling\n",
      "hands-free\n",
      "communication\n",
      "and\n",
      "transcription\n",
      "hidden\n",
      "markov\n",
      "models\n",
      "hmms\n",
      "and\n",
      "deep\n",
      "learning\n",
      "models\n",
      "such\n",
      "as\n",
      "recurrent\n",
      "neural\n",
      "networks\n",
      "rnns\n",
      "and\n",
      "convolutional\n",
      "neural\n",
      "networks\n",
      "cnns\n",
      "are\n",
      "commonly\n",
      "employed\n",
      "in\n",
      "speech\n",
      "recognition\n",
      "these\n",
      "models\n",
      "learn\n",
      "acoustic\n",
      "and\n",
      "language\n",
      "models\n",
      "to\n",
      "decode\n",
      "spoken\n",
      "words\n",
      "and\n",
      "transcribe\n",
      "them\n",
      "accurately\n",
      "nlp\n",
      "has\n",
      "witnessed\n",
      "remarkable\n",
      "advancements\n",
      "in\n",
      "recent\n",
      "years\n",
      "due\n",
      "to\n",
      "the\n",
      "availability\n",
      "of\n",
      "large-scale\n",
      "datasets\n",
      "computational\n",
      "resources\n",
      "and\n",
      "breakthroughs\n",
      "in\n",
      "deep\n",
      "learning\n",
      "transfer\n",
      "learning\n",
      "pre-training\n",
      "and\n",
      "fine-tuning\n",
      "techniques\n",
      "have\n",
      "revolutionized\n",
      "the\n",
      "field\n",
      "by\n",
      "enabling\n",
      "models\n",
      "to\n",
      "learn\n",
      "from\n",
      "vast\n",
      "amounts\n",
      "of\n",
      "general-domain\n",
      "text\n",
      "data\n",
      "models\n",
      "such\n",
      "as\n",
      "bert\n",
      "bidirectional\n",
      "encoder\n",
      "representations\n",
      "from\n",
      "transformers\n",
      "and\n",
      "gpt\n",
      "generative\n",
      "pre-trained\n",
      "transformer\n",
      "have\n",
      "achieved\n",
      "state-of-the-art\n",
      "results\n",
      "in\n",
      "various\n",
      "nlp\n",
      "tasks\n",
      "by\n",
      "leveraging\n",
      "contextual\n",
      "word\n",
      "representations\n",
      "and\n",
      "transformer\n",
      "architectures\n",
      "in\n",
      "conclusion\n",
      "nlp\n",
      "has\n",
      "emerged\n",
      "as\n",
      "a\n",
      "fascinating\n",
      "field\n",
      "that\n",
      "allows\n",
      "machines\n",
      "to\n",
      "understand\n",
      "interpret\n",
      "and\n",
      "generate\n",
      "human\n",
      "language\n",
      "from\n",
      "analyzing\n",
      "sentiments\n",
      "and\n",
      "translating\n",
      "languages\n",
      "to\n",
      "enabling\n",
      "chatbots\n",
      "and\n",
      "speech\n",
      "recognition\n",
      "systems\n",
      "nlp\n",
      "has\n",
      "found\n",
      "applications\n",
      "in\n",
      "diverse\n",
      "domains\n",
      "as\n",
      "advancements\n",
      "in\n",
      "machine\n",
      "learning\n",
      "and\n",
      "deep\n",
      "learning\n",
      "continue\n",
      "to\n",
      "propel\n",
      "the\n",
      "field\n",
      "forward\n",
      "nlp\n",
      "holds\n",
      "immense\n",
      "potential\n",
      "for\n",
      "further\n",
      "breakthroughs\n",
      "making\n",
      "human-computer\n",
      "interaction\n",
      "more\n",
      "seamless\n",
      "and\n",
      "natural\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Input Data/paragraph.txt\", \"r\")\n",
    "s = f.readlines()\n",
    "\n",
    "s[0] = s[0][3:]\n",
    "new_li = []\n",
    "\n",
    "\n",
    "for it in s:\n",
    "    li = it.split(\" \")\n",
    "    punct = ['','\\n','.', ',', '?', '!', ':', ';', '...', '(', ')']\n",
    "    for ele in li:\n",
    "        if ele not in punct:\n",
    "            for char in punct:\n",
    "                ele = ele.strip(char)\n",
    "            ele = ele.lower()\n",
    "            new_li.append(ele)\n",
    "\n",
    "for ele in new_li:\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a664e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_count = 0\n",
    "f = open(\"Input Data/paragraph.txt\", \"r\")\n",
    "s = f.read()\n",
    "s = s[3:]\n",
    "\n",
    "\n",
    "for ele in s:\n",
    "    if ele == '.':\n",
    "        sentence_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ca7d66d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of words:  670\n",
      "Total no. of sentences:  36\n"
     ]
    }
   ],
   "source": [
    "print(\"Total no. of words: \", len(new_li))\n",
    "print(\"Total no. of sentences: \", sentence_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ad9b3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>and</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>the</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>to</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>in</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word  Frequency\n",
       "18  and         37\n",
       "31  the         22\n",
       "7    of         20\n",
       "15   to         19\n",
       "39   in         15"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word count\n",
    "\n",
    "word_freq_dict = {}\n",
    "for ele in new_li:\n",
    "    if ele not in word_freq_dict:\n",
    "        word_freq_dict[ele] = 1\n",
    "    else:\n",
    "        word_freq_dict[ele] += 1\n",
    "        \n",
    "        \n",
    "data = {'Word': list(word_freq_dict.keys()),\n",
    "        'Frequency': list(word_freq_dict.values())} \n",
    "new = pd.DataFrame.from_dict(data)\n",
    "  \n",
    "new = new.sort_values(by = 'Frequency', ascending = False)\n",
    "new.to_csv('Output Data/Q2. Word Frequency.csv', index = False)\n",
    "\n",
    "\n",
    "\n",
    "# displaying top 5 most frequent words\n",
    "new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "206c96c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score:  21\n"
     ]
    }
   ],
   "source": [
    "# positive score\n",
    "\n",
    "positive_score = 0\n",
    "\n",
    "\n",
    "f = open(\"Input Data/positive-words.txt\", \"r\")\n",
    "s = f.readlines()\n",
    "#print(s)\n",
    "\n",
    "positive_words = []\n",
    "for it in s:\n",
    "    it = it.strip('\\n')\n",
    "    positive_words.append(it)\n",
    "\n",
    "#print(positive_words)\n",
    "for word, freq in word_freq_dict.items():\n",
    "    if word in positive_words:\n",
    "        #print(word, \" \", freq)\n",
    "        positive_score += freq\n",
    "\n",
    "print(\"Positive Score: \", positive_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5cb855a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Score:  4\n"
     ]
    }
   ],
   "source": [
    "# negative score\n",
    "\n",
    "negative_score = 0\n",
    "\n",
    "\n",
    "f = open(\"Input Data/negative-words.txt\", \"r\")\n",
    "s = f.readlines()\n",
    "#print(s)\n",
    "\n",
    "negative_words = []\n",
    "for it in s:\n",
    "    it = it.strip('\\n')\n",
    "    negative_words.append(it)\n",
    "\n",
    "#print(positive_words)\n",
    "for word, freq in word_freq_dict.items():\n",
    "    if word in negative_words:\n",
    "        #print(word)\n",
    "        negative_score += freq\n",
    "\n",
    "print(\"Negative Score: \", negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "12be9366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polarity Score:  0.68\n"
     ]
    }
   ],
   "source": [
    "# polarity score\n",
    "\n",
    "polarity_score = (positive_score - negative_score) / (positive_score + negative_score + 0.000001)\n",
    "print(\"Polarity Score: \", round(polarity_score,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "07bb2f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of words:  670\n",
      "Total no. of sentences:  36\n",
      "\n",
      "\n",
      "Average Sentence Length:  18.61\n"
     ]
    }
   ],
   "source": [
    "# average sentence length\n",
    "\n",
    "print(\"Total no. of words: \", len(new_li))\n",
    "print(\"Total no. of sentences: \", sentence_count)\n",
    "print()\n",
    "print()\n",
    "print(\"Average Sentence Length: \", round(len(new_li)/sentence_count , 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
